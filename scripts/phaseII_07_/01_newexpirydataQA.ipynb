{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test new data\n",
    "Client has provided new query for obtaining expiry data (`./expiry_prepped_data.sql`)\n",
    "\n",
    "Verifying that query returns data that's usable by existing scripts\n",
    "\n",
    "\n",
    "In general: Steps for running queries provided by client\n",
    "\n",
    "0. ensure w/ client that they have set you up with necessary Permissions to query their Project's tables.\n",
    "1. make sure query definition points to correct Project name (radixbi-249015) by appending this to every table call (FROM statement) that fails to mention it (i.e. change prediction_vendors.predictions to radixbi-249015.prediction_vendors.predictions) otherwise, BuigQuery will default to whichever project you're working in.\n",
    "2. in BigQuery, run query \n",
    "3. in BigQuery, save results to BigQuery table (this will create a table in your project)\n",
    "4. in R, use bigrquery package to load data in memory<br>\n",
    "``sql <- paste(\"SELECT * FROM `radix2020.expiry.new_test`\")\n",
    "new_test_df <- bq_table_download(bq_project_query(\"radix2020\", sql))``\n",
    "\n",
    "I've created a new BigQuery table (`radix2020.expiry.new_test`) that has just the first 100 results of this query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO for John:\n",
    "\n",
    "1. Modify load_prep_data_expiry_2.R such that the date filter is dynamic, \n",
    "    - we don't want to analyze data that is 'premature' -- renewal status lags 90 days (so domains that expired today won't have a correct renewal status until 90 days from today).\n",
    "    - in general, we want to analyze 5 quarters of data \n",
    "    - implement the above as a script argument (like min date and max date) to kill two birds with one stone\n",
    "    - we could also just bake this into the intial data pull (i.e. modify date constraints in 2 above)\n",
    "2. Create a script that, when given the name of a \"local\" BigQuery table (such as radix2020.expiry.new_test), first runs load_prep_data_expiry_2.R and then predictions_metalearning.R. This will generate a file of predictions across all models\n",
    "3. Cleate a cleaner version of training_metalearning.R, \n",
    "    - one that uses predictions from (2) (maybe as a script argument?) \n",
    "    - may be split into two scripts -- one that trains the metalearning model and one that generates predictions on a new dataset\n",
    "    - good idea to create a separate script file that contains functions (similar to how predictions_metalearning.R is kept \"lean\" and easy to read)\n",
    "4. ensure output is in line with Radix request \n",
    "    - expiry data columns + prediction column + model name column + model version/info column\n",
    "    - write to bigquery table\n",
    "    - see 16_fallbackmeta_analysis_deliv.ipynb for part of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bigrquery)\n",
    "library(plotly)\n",
    "library(data.table)\n",
    "library(stringr)\n",
    "library(readr)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull new data 02/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following work around does not seem to be necessary for this new data set\n",
    "# https://community.exploratory.io/t/google-bigquery-import-fails-with-invalid-value-at-start-index-type-uint64-1e-05-invalid/1901\n",
    "# options(scipen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql <- paste(\"SELECT * FROM `radix2020.expiry.new_test`\")\n",
    "new_test_df <- bq_table_download(bq_project_query(\"radix2020\", sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>100</li><li>30</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 100\n",
       "\\item 30\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 100\n",
       "2. 30\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 100  30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following writes data to an RDS on the virtual machine and then copies it to an already created Google Cloud Storage bucket location\n",
    "# saveRDS(expiry_20200902_20201102_20201127,\"../../data/output/datapull_20201127/expiry_20200902_20201102_20201127\")\n",
    "# system(\"gsutil cp /home/jupyter/local/Domains_202003/data/output/datapull_20201127/* gs://data_outputt/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_prep_data_expiry_2.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...Loaded 100 rows\n",
      "Removing 68 rows due to expiry_date constraints\n",
      "Removing 4 rows due to renewed_count constraints\n",
      "Removing 0 rows due to missing gibb_score\n",
      "... now dataset min(creation_date) is  2018-06-08 .\n"
     ]
    }
   ],
   "source": [
    "cat(\"Loading data...\")\n",
    "expiry_df <- new_test_df#readRDS(\"/home/jupyter/Domains_202003/data/output/expiry_20190601_20200901_20201116_excl\")\n",
    "cat(\"Loaded\", expiry_df %>% nrow(),\"rows\\n\")\n",
    "\n",
    "# select most recent 5Q [1 quarter = 90 days, 5 quarters = 450 days ]\n",
    "# 450 days before 20200901 is 20190609 ... round off to 20190601\n",
    "cat(\"Removing\", expiry_df %>%filter(expiry_date < as.Date(\"2019-06-01\") | expiry_date > as.Date(\"2020-09-01\")) %>% tally() %>% pull(n) ,\"rows due to expiry_date constraints\\n\")\n",
    "expiry_df <- expiry_df %>% filter(expiry_date >= as.Date(\"2019-06-01\") & expiry_date <= as.Date(\"2020-09-01\"))\n",
    "\n",
    "# remove renewed_count>1\n",
    "cat(\"Removing\", expiry_df %>% filter(renewed_count>1) %>% tally() %>% pull(n) ,\"rows due to renewed_count constraints\\n\")\n",
    "expiry_df <- expiry_df %>% filter(renewed_count==1)\n",
    "\n",
    "# remove where gibb_score, etc. are NA\n",
    "cat(\"Removing\", expiry_df %>% filter(is.na(gibb_score)) %>% tally() %>% pull(n) ,\"rows due to missing gibb_score\\n\")\n",
    "expiry_df <- expiry_df %>% filter(!is.na(gibb_score))\n",
    "cat(\"... now dataset min(creation_date) is \", expiry_df %>% summarise(min(creation_date)) %>% pull(1) %>% as.character(),\".\\n\")\n",
    "\n",
    "# add necessary columns\n",
    "expiry_df <- expiry_df %>% mutate (reg_arpt = ifelse(reg_arpt <= 0, 0.0001,reg_arpt),\n",
    "                                   log_reg_arpt = log(reg_arpt),\n",
    "                                   tld_registrar_index = tolower(paste(tld, reseller,sep=\"\")))\n",
    "\n",
    "# test/train split \n",
    "set.seed(123) \n",
    "smp_siz = floor(0.8*nrow(expiry_df))\n",
    "train_ind = sample(seq_len(nrow(expiry_df)),size = smp_siz) \n",
    "expiry_train_df = expiry_df[train_ind,] \n",
    "expiry_test_df = expiry_df[-train_ind,]\n",
    "\n",
    "# split into lists\n",
    "expiry_list <- split(expiry_df, expiry_df$tld_registrar_index)\n",
    "expiry_train_list <- split(expiry_train_df, expiry_train_df$tld_registrar_index)\n",
    "expiry_test_list <- split(expiry_test_df, expiry_test_df$tld_registrar_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>28</li><li>32</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 28\n",
       "\\item 32\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 28\n",
       "2. 32\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 28 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>22</li><li>32</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 22\n",
       "\\item 32\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 22\n",
       "2. 32\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 22 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>6</li><li>32</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 6\n",
       "\\item 32\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 6\n",
       "2. 32\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  6 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(expiry_df)\n",
    "dim(expiry_train_df)\n",
    "dim(expiry_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions_metalearning\n",
    "Not excluding any low-vol tld-re's using tld_registrar_excl() because dataet is already so small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & prep input data\n",
    "source('/home/jupyter/Domains_202003/scripts/orig/functions_models.R')\n",
    "source('/home/jupyter/Domains_202003/scripts/phaseII_03_forest/functions_eval.R')\n",
    "source('/home/jupyter/Domains_202003/scripts/phaseII_06_fallbacksupp/functions_metalearning.R')\n",
    "# source('/home/jupyter/Domains_202003/scripts/phaseII_06_fallbacksupp/load_prep_data_expiry_2.R')\n",
    "# defines expiry_df & list of expiry_20180101_20190331\n",
    "# as well as expiry_train_df, expiry_test_df,  expiry_train_list, expiry_test_list\n",
    "\n",
    "\n",
    "# define oputput folder\n",
    "fullDir='/home/jupyter/Domains_202003/data/output/models_20201104'\n",
    "dir.create(fullDir)\n",
    "dir.create(file.path(fullDir,'preds'))\n",
    "\n",
    "# define tld-re's for training\n",
    "tld_reseller_list = expiry_train_df %>%  distinct(tld_registrar_index) %>% pull(tld_registrar_index)\n",
    "tld_registrar_excl_list = list() #tld_registrar_excl(train_list = expiry_train_list)\n",
    "\n",
    "# train & save models\n",
    "tld_reseller_list = train_all(  tld_reseller_list,\n",
    "                                tld_registrar_excl_list,\n",
    "                                train_list = expiry_train_list,\n",
    "                                test_list = expiry_test_list,\n",
    "                                model_agg_glm = NULL, \n",
    "                                model_agg_rf = NULL,\n",
    "                                fullDir)   \n",
    "\n",
    "# define tld-re's for testing\n",
    "tld_reseller_list = expiry_test_df %>%  distinct(tld_registrar_index) %>% pull(tld_registrar_index)\n",
    "tld_registrar_excl_list=list() #= tld_registrar_excl(train_list = expiry_train_list)\n",
    "\n",
    "# predict based on saved models\n",
    "preds_df <- pred_all(tld_reseller_list, tld_registrar_excl_list,\n",
    "                     test_list = expiry_test_list,\n",
    "                     modelDir=fullDir,\n",
    "                     fullDir=fullDir)\n",
    "\n",
    "# write.csv(preds_df, file=file.path(fullDir,'preds','preds.csv'),row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m48"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
